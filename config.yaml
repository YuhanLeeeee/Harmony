mlp_model:  # fingerprint encoder
  mlp_hidden_size: 256
  dense_layers: 4
  sparse_layers: 2
  num_experts: 4
  dropout_ratio: 0.1
  output_dim: 1024

graph_model:  # 2D graph encoder -> Important! For the BH and SM dataset, set it to 64-2-3-1. For the ACR datasets, set it to 32-1-1-1.
  hidden_size: 64
  num_step_mp: 2
  num_step_set2set: 3
  num_layer_set2set: 1
  output_dim: 1024

smiles_model:  # SMILES encoder
  embed_dim: 512
  num_heads: 4
  context_length: 1024
  num_layers: 2
  output_dim: 1024

predictor:  # late fusion
  hidden_size: 1024
  dropout_ratio: 0.1

training:
  batch_size: 128
  lr: 0.0005
  weight_decay: 0.00005
  epochs: 0
  patience: 300
  cuda: 0
  train_ratio: 1.0
#  BH
#  exp_name: 'Harmony_BH'
#  dataset_path: "./data/BH_split.pkl"
#  SM
  exp_name: 'Harmony_SM'
  dataset_path: "./data/SM_split.pkl"
#  ACR
#  exp_name: 'Harmony_ACR'
#  dataset_path: "./data/ACR_split622.pkl"
  pretrained: False

# BH 2768 1187 MAE: 2.651, MSE: 3.987, R2: 0.979
# SM 4031 1729 MAE: 5.814, MSE: 9.279, R2: 0.890
# ACR 24627 8206 8211 MAE: 14.860, MSE: 18.878, R2: 0.320